# -*- coding: utf-8 -*-
"""Optimizacion Quirófanos

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DzClzUbcOYiRa8pFWNXGY1L_jNy7BMhi
"""

"""
OR-Master: Sistema de Optimización de Tiempos Quirúrgicos (Versión CDSS)
Descripción: Simulación, modelado predictivo, auditoría financiera y Sistema de Soporte a la Decisión Clínica.
"""

import sys
import logging
import joblib
from dataclasses import dataclass
from typing import Tuple, Dict, List, Optional, Any

# Configuración de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler(sys.stdout)],
    force=True
)
logger = logging.getLogger("OR_MASTER_AI")

try:
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    import matplotlib.gridspec as gridspec
    import seaborn as sns
    from sklearn.model_selection import train_test_split, RandomizedSearchCV
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.pipeline import Pipeline
    from sklearn.compose import ColumnTransformer
    from sklearn.preprocessing import OneHotEncoder, StandardScaler
    from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score, mean_squared_error

    # Intentar importar SHAP para explicabilidad avanzada
    try:
        import shap
        SHAP_AVAILABLE = True
    except ImportError:
        SHAP_AVAILABLE = False
        logger.warning("Librería 'shap' no encontrada. Se usará explicabilidad básica.")

except ImportError as e:
    logger.error(f"Error de dependencia crítica: {e}")
    sys.exit(1)

plt.style.use('seaborn-v0_8-whitegrid')
sns.set_context("paper", font_scale=1.1)
sns.set_palette("deep")

@dataclass
class ConfigQuirofano:
    """Configuración del sistema."""
    N_MUESTRAS: int = 5000
    COSTO_MINUTO_SUBESTIMADO: float = 100.0
    COSTO_MINUTO_SOBREESTIMADO: float = 50.0
    UMBRAL_CRITICO_MIN: int = 30
    SEED: int = 42

class GeneradorDatosQuirofano:
    """Generador de datos sintéticos (Digital Twin) con caos realista."""

    def __init__(self, config: ConfigQuirofano):
        self.cfg = config
        np.random.seed(self.cfg.SEED)

    def _redondear_a_bloque(self, minutos, bloque=15):
        return np.ceil(minutos / bloque) * bloque

    def _simular_complejidad_biologica(self, df: pd.DataFrame) -> np.ndarray:
        base_times = {
            'Colecistectomía': 60, 'Reemplazo Cadera': 120,
            'Hernia Inguinal': 50, 'Bypass Gástrico': 160, 'Craneotomía': 240
        }

        duracion_base = df['procedimiento'].map(base_times)

        # Factores no lineales
        es_abdominal = df['procedimiento'].isin(['Colecistectomía', 'Bypass Gástrico', 'Hernia Inguinal'])
        factor_obesidad = np.where((df['imc_paciente'] > 35) & es_abdominal, (df['imc_paciente']-30)*2.0, 0)
        factor_asa = (df['asa_score'] ** 1.8) * 4

        velocidad_map = {'Dr. Rápido': 0.85, 'Dra. Meticulosa': 1.15, 'Dr. Residente': 1.4, 'Dra. Senior': 0.95}
        factor_cirujano = df['cirujano'].map(velocidad_map)

        # Ruido Log-Normal (Caos)
        caos_irreductible = np.random.lognormal(mean=0, sigma=0.15, size=len(df))

        tiempo_calculado = (duracion_base + factor_obesidad + factor_asa) * factor_cirujano
        tiempo_real = tiempo_calculado * caos_irreductible

        return tiempo_real.clip(lower=30).astype(int)

    def generar_dataset(self) -> pd.DataFrame:
        logger.info(f"Generando Digital Twin ({self.cfg.N_MUESTRAS} casos)...")
        n = self.cfg.N_MUESTRAS
        data = {
            'procedimiento': np.random.choice(['Colecistectomía', 'Reemplazo Cadera', 'Hernia Inguinal', 'Bypass Gástrico', 'Craneotomía'], n),
            'cirujano': np.random.choice(['Dr. Rápido', 'Dra. Meticulosa', 'Dr. Residente', 'Dra. Senior'], n),
            'edad_paciente': np.random.randint(18, 95, n),
            'imc_paciente': np.random.normal(29, 7, n),
            'asa_score': np.random.choice([1, 2, 3, 4], n, p=[0.3, 0.4, 0.2, 0.1]),
            'turno': np.random.choice(['Mañana', 'Tarde', 'Noche'], n, p=[0.5, 0.4, 0.1])
        }
        df = pd.DataFrame(data)
        df['duracion_real'] = self._simular_complejidad_biologica(df)

        # Agenda Humana (Block Scheduling)
        base_times_human = df['procedimiento'].map({'Colecistectomía': 70, 'Reemplazo Cadera': 130, 'Hernia Inguinal': 60, 'Bypass Gástrico': 170, 'Craneotomía': 250})
        estimacion_cruda = base_times_human + np.random.normal(0, 10, n)
        df['agenda_humana'] = self._redondear_a_bloque(estimacion_cruda, bloque=15).astype(int)

        return df

class OptimizadorQuirofanoIA:
    """Motor de IA con capacidades de explicabilidad (SHAP)."""

    def __init__(self):
        self.model = None
        self.feature_names = None
        self.preprocessor = None

    def entrenar(self, X: pd.DataFrame, y: pd.Series, optimizar: bool = True):
        logger.info("Entrenando modelo predictivo...")

        categorical_cols = ['procedimiento', 'cirujano', 'turno']
        numerical_cols = ['edad_paciente', 'imc_paciente', 'asa_score']

        # Preprocesador separado para usarlo luego en inferencia individual
        self.preprocessor = ColumnTransformer(
            transformers=[
                ('num', StandardScaler(), numerical_cols),
                ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)
            ])

        pipeline_base = Pipeline(steps=[
            ('preprocessor', self.preprocessor),
            ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1))
        ])

        if optimizar:
            logger.info("Optimizando hiperparámetros (RandomizedSearchCV)...")
            param_dist = {
                'regressor__n_estimators': [150, 250],
                'regressor__max_depth': [10, 15, None],
                'regressor__min_samples_leaf': [2, 4]
            }
            search = RandomizedSearchCV(pipeline_base, param_distributions=param_dist,
                                      n_iter=3, cv=3, scoring='neg_root_mean_squared_error',
                                      random_state=42, n_jobs=-1)
            search.fit(X, y)
            self.model = search.best_estimator_
        else:
            pipeline_base.set_params(regressor__n_estimators=200, regressor__max_depth=12)
            self.model = pipeline_base
            self.model.fit(X, y)

        # Recuperar nombres de features transformadas
        try:
            ohe = self.model.named_steps['preprocessor'].named_transformers_['cat']
            ohe_features = ohe.get_feature_names_out(categorical_cols)
            self.feature_names = numerical_cols + list(ohe_features)
        except Exception as e:
            logger.warning(f"No se pudieron extraer nombres de features: {e}")
            self.feature_names = [f"feat_{i}" for i in range(50)]

        logger.info("Modelo listo.")

    def predecir(self, X: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """Devuelve predicción puntual y desviación estándar (incertidumbre)."""
        # Hack para obtener incertidumbre de RandomForest: desviación estándar de los árboles
        preds = []
        regressor = self.model.named_steps['regressor']
        X_trans = self.model.named_steps['preprocessor'].transform(X)

        for estimator in regressor.estimators_:
            preds.append(estimator.predict(X_trans))

        preds = np.array(preds)
        mean_pred = np.mean(preds, axis=0)
        std_pred = np.std(preds, axis=0)

        return mean_pred, std_pred

    def obtener_importancia_variables(self) -> pd.DataFrame:
        if not self.model: return pd.DataFrame()
        importances = self.model.named_steps['regressor'].feature_importances_
        # Ajuste de longitud seguro
        n_feats = min(len(self.feature_names), len(importances))
        return pd.DataFrame({'feature': self.feature_names[:n_feats], 'importance': importances[:n_feats]}).sort_values(by='importance', ascending=False)

    def explicar_instancia(self, df_instancia: pd.DataFrame):
        """Genera explicación SHAP para un caso específico (si está disponible)."""
        if not SHAP_AVAILABLE:
            return None

        # Preparar datos transformados
        X_trans = self.model.named_steps['preprocessor'].transform(df_instancia)
        regressor = self.model.named_steps['regressor']

        # Crear explainer (TreeExplainer es eficiente para RF)
        explainer = shap.TreeExplainer(regressor)
        shap_values = explainer.shap_values(X_trans)

        return shap_values, X_trans

class AuditoriaFinanciera:
    """Motor de cálculo de ROI."""

    def __init__(self, config: ConfigQuirofano):
        self.cfg = config

    def calcular_impacto(self, y_real: np.ndarray, y_agendado: np.ndarray) -> Dict:
        error = y_real - y_agendado
        costo = np.where(error > 0, error * self.cfg.COSTO_MINUTO_SUBESTIMADO, np.abs(error) * self.cfg.COSTO_MINUTO_SOBREESTIMADO)
        casos_criticos = np.sum(np.abs(error) > self.cfg.UMBRAL_CRITICO_MIN)

        return {
            'costo_total': np.sum(costo),
            'mape': mean_absolute_percentage_error(y_real, y_agendado),
            'rmse': np.sqrt(mean_squared_error(y_real, y_agendado)),
            'mae': mean_absolute_error(y_real, y_agendado),
            'casos_criticos_pct': casos_criticos / len(y_real),
            'r2': r2_score(y_real, y_agendado)
        }

class CDSS_Simulator:
    """Clinical Decision Support System: Simulador interactivo para la consola."""

    @staticmethod
    def simular_casos(engine: OptimizadorQuirofanoIA):
        print("\n" + "="*80)
        print("CDSS - SIMULADOR DE CASOS CLÍNICOS (Inferencia en Tiempo Real)")
        print("="*80)

        casos = [
            {
                'procedimiento': 'Bypass Gástrico', 'cirujano': 'Dr. Residente',
                'edad_paciente': 45, 'imc_paciente': 45.0, 'asa_score': 3, 'turno': 'Mañana',
                'desc': 'Paciente Obeso Mórbido (IMC 45) con Residente'
            },
            {
                'procedimiento': 'Hernia Inguinal', 'cirujano': 'Dra. Senior',
                'edad_paciente': 30, 'imc_paciente': 24.0, 'asa_score': 1, 'turno': 'Mañana',
                'desc': 'Paciente Joven Sano con Experta'
            }
        ]

        for caso in casos:
            df_caso = pd.DataFrame([caso])
            pred_media, pred_std = engine.predecir(df_caso)

            # Agenda humana típica (Block Scheduling)
            agenda_humana = 180 if caso['procedimiento'] == 'Bypass Gástrico' else 60

            print(f"\n CASO: {caso['desc']}")
            print(f"   Agenda Humana Típica: {agenda_humana} min")
            print(f"   PREDICCIÓN IA:     {pred_media[0]:.0f} min (±{pred_std[0]*2:.0f} min IC 95%)")

            delta = pred_media[0] - agenda_humana
            if abs(delta) > 15:
                accion = "ALERTA: AJUSTAR AGENDA"
                motivo = "Riesgo de subestimación grave" if delta > 0 else "Oportunidad de eficiencia"
                print(f"   {accion} ({delta:+.0f} min). Motivo: {motivo}")
            else:
                print(f"   Agenda adecuada.")

class DashboardEjecutivo:
    @staticmethod
    def generar_reporte(y_real, y_pred, y_human, feature_importance, metrics_human, metrics_ai, ahorro):
        fig = plt.figure(figsize=(16, 10))
        gs = gridspec.GridSpec(2, 2)
        fig.suptitle('Optimización Quirúrgica: Humano vs IA', fontsize=20, fontweight='bold', y=0.96)

        # 1. Scatter Plot
        ax1 = plt.subplot(gs[0, 0])
        subset = 300
        ax1.scatter(y_real[:subset], y_human[:subset], alpha=0.4, color='red', label='Humano (Block Scheduling)', marker='s', s=20)
        ax1.scatter(y_real[:subset], y_pred[:subset], alpha=0.5, color='green', label='IA (Precision)', marker='o', s=20)
        ax1.plot([0, 450], [0, 450], 'k--', lw=1)
        ax1.set_title(f"Precisión (R²: {metrics_human['r2']:.2f} ➝ {metrics_ai['r2']:.2f})")
        ax1.set_xlabel("Real"); ax1.set_ylabel("Estimado")
        ax1.legend()

        # 2. Distribución de Errores
        ax2 = plt.subplot(gs[0, 1])
        sns.histplot(y_real - y_human, color='red', kde=True, ax=ax2, alpha=0.3, label='Error Humano')
        sns.histplot(y_real - y_pred, color='green', kde=True, ax=ax2, alpha=0.3, label='Error IA')
        ax2.axvline(0, color='k', linestyle='--')
        ax2.set_title("Distribución de Incertidumbre")
        ax2.legend()

        # 3. Feature Importance
        ax3 = plt.subplot(gs[1, 0])
        top = feature_importance.head(8).sort_values(by='importance', ascending=True)
        ax3.barh(top['feature'], top['importance'], color='steelblue')
        ax3.set_title("Drivers de Complejidad")

        # 4. KPI Box
        ax4 = plt.subplot(gs[1, 1])
        ax4.axis('off')
        txt = (f"IMPACTO ANUAL:\n${ahorro:,.0f} USD\n\n"
               f"REDUCCIÓN MAE:\n{metrics_human['mae']:.0f} min ➝ {metrics_ai['mae']:.0f} min\n\n"
               f"CASOS CRÍTICOS:\n{(metrics_human['casos_criticos_pct']*100):.1f}% ➝ {(metrics_ai['casos_criticos_pct']*100):.1f}%")
        ax4.text(0.5, 0.5, txt, ha='center', va='center', fontsize=16, bbox=dict(boxstyle="round", fc="ivory"))

        plt.tight_layout(rect=[0, 0, 1, 0.95])
        plt.show()

def main():
    config = ConfigQuirofano()
    generador = GeneradorDatosQuirofano(config)
    auditor = AuditoriaFinanciera(config)
    ai_engine = OptimizadorQuirofanoIA()

    # Datos
    df = generador.generar_dataset()
    X = df.drop(['duracion_real', 'agenda_humana'], axis=1)
    y = df['duracion_real']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=X['procedimiento'])

    # Entrenamiento
    ai_engine.entrenar(X_train, y_train, optimizar=True)

    # Inferencia (con incertidumbre)
    y_pred, y_std = ai_engine.predecir(X_test)
    y_human = df.loc[y_test.index, 'agenda_humana'].values

    # Métricas
    m_human = auditor.calcular_impacto(y_test.values, y_human)
    m_ai = auditor.calcular_impacto(y_test.values, y_pred)
    ahorro = (m_human['costo_total'] - m_ai['costo_total']) * 12

    # Reporte
    print(f"\n AHORRO ANUAL PROYECTADO: ${ahorro:,.2f} USD")
    DashboardEjecutivo.generar_reporte(y_test.values, y_pred, y_human, ai_engine.obtener_importancia_variables(), m_human, m_ai, ahorro)

    # Simulación Interactiva (NUEVO)
    CDSS_Simulator.simular_casos(ai_engine)

if __name__ == "__main__":
    main()